{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Load the model from .h5 file\n",
    "model = keras.models.load_model('D:\\AMRITA COLLEGE\\SEM 6\\Maths\\Project\\discriminator500.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers of the pre-trained model\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new layers for classification\n",
    "input_layer = keras.Input(shape=(28, 28, 1))\n",
    "x = keras.layers.Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "x = keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "output_layer = keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "# Combine the pre-trained model and new layers\n",
    "model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "MAIN_DIR = \"\"\n",
    "SEED = 40\n",
    "os.listdir(MAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder):\n",
    "    imgs = []\n",
    "    target = 0\n",
    "    labels = []\n",
    "    for i in os.listdir(folder):\n",
    "        subdir = os.path.join(folder, i)\n",
    "        for j in os.listdir(subdir):\n",
    "            img_dir = os.path.join(subdir,j)\n",
    "            try:\n",
    "                img = cv2.imread(img_dir)\n",
    "                if img.shape[-1] == 1:\n",
    "                    # convert grayscale image to RGB\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "                img = cv2.resize(img,(224,224))\n",
    "                imgs.append(img)\n",
    "                labels.append(target)\n",
    "            except:\n",
    "                continue\n",
    "        target += 1\n",
    "    \n",
    "    imgs = np.array(imgs)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = load_images(MAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "y = encoder.transform(labels)\n",
    "\n",
    "y_one_hot = to_categorical(y, num_classes=2) # One-hot encode the target variable\n",
    "\n",
    "norm_data = data / 255. \n",
    "norm_data.shape, norm_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the split datasets\n",
    "print(\"Train Data Shape:\", train_data.shape)\n",
    "print(\"Train Labels Shape:\", train_labels.shape)\n",
    "print(\"Test Data Shape:\", test_data.shape)\n",
    "print(\"Test Labels Shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert target labels to one-hot encoded format\n",
    "train_labels = to_categorical(train_labels, num_classes=20)\n",
    "test_labels = to_categorical(test_labels, num_classes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=2\n",
    "batch_size=5\n",
    "model.fit(train_data,train_labels, epochs=num_epochs, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data,train_labels, epochs=num_epochs, batch_size=batch_size, validation_data=(train_labels,test_labels))\n",
    "\n",
    "# Plot accuracy curve\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot loss curve\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
